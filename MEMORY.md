# Aplicaci√≥n Web de Escaneo de Documentos con T√©cnicas de Visi√≥n por Computador

![Imagen car√°tula del proyecto](assets/cover.png)

**Autores**

- Marcos V√°zquez Tasc√≥n
- Francisco Javier L√≥pez-Dufour Morales

**Enlaces Principales**

üîó **Repositorio Principal**: [https://github.com/gitfrandu4/docu-scan](https://github.com/gitfrandu4/docu-scan)

üåê **Despliegue**: [gitfrandu4.github.io/docu-scan/](https://gitfrandu4.github.io/docu-scan/)

<div class="page"/>

## √çndice

- [Aplicaci√≥n Web de Escaneo de Documentos con T√©cnicas de Visi√≥n por Computador](#aplicaci√≥n-web-de-escaneo-de-documentos-con-t√©cnicas-de-visi√≥n-por-computador)
  - [√çndice](#√≠ndice)
  - [Motivaci√≥n y Argumentaci√≥n](#motivaci√≥n-y-argumentaci√≥n)
  - [Objetivo de la Propuesta](#objetivo-de-la-propuesta)
    - [Objetivo Principal](#objetivo-principal)
    - [Objetivos Espec√≠ficos](#objetivos-espec√≠ficos)
  - [Descripci√≥n T√©cnica](#descripci√≥n-t√©cnica)
    - [Desarrollo del Pipeline de Procesamiento en Python](#desarrollo-del-pipeline-de-procesamiento-en-python)
    - [Pruebas de Concepto con OCR](#pruebas-de-concepto-con-ocr)
    - [Arquitectura del Sistema](#arquitectura-del-sistema)
    - [Tecnolog√≠as Implementadas](#tecnolog√≠as-implementadas)
  - [Fuentes y Tecnolog√≠as Utilizadas](#fuentes-y-tecnolog√≠as-utilizadas)
    - [Software](#software)
    - [Hardware](#hardware)
    - [Bibliotecas y Dependencias](#bibliotecas-y-dependencias)
  - [Resultados](#resultados)
    - [Entrenamiento del Modelo](#entrenamiento-del-modelo)
    - [Resultados del Entrenamiento](#resultados-del-entrenamiento)
    - [Ejemplo de Inferencia](#ejemplo-de-inferencia)
  - [Conclusiones y Propuestas de Ampliaci√≥n](#conclusiones-y-propuestas-de-ampliaci√≥n)
    - [Conclusiones](#conclusiones)
    - [Propuestas de Ampliaci√≥n](#propuestas-de-ampliaci√≥n)
  - [Enlaces](#enlaces)
  - [Cr√©ditos](#cr√©ditos)

<div class="page"/>

## Motivaci√≥n y Argumentaci√≥n

En una sociedad que avanza r√°pidamente hacia la **digitalizaci√≥n** de los procesos y la reducci√≥n de documentos f√≠sicos, contar con herramientas que faciliten la **captura, mejora y gesti√≥n de documentos** se ha convertido en una necesidad ineludible. Fotografiar o escanear documentos (contratos, recibos, facturas, informes, apuntes acad√©micos, etc.) de forma r√°pida y fiable es un requisito no solo para las grandes empresas, sino tambi√©n para usuarios individuales y peque√±os negocios.

Los retos m√°s comunes que se presentan en esta tarea son:

- **Condiciones de iluminaci√≥n y enfoque** inadecuadas, que degradan la calidad de las im√°genes.
- **Perspectivas err√≥neas** (folios doblados o torcidos) que impiden una correcta lectura o extracci√≥n de texto.
- **Procesos de OCR** (Reconocimiento √ìptico de Caracteres) que fallan cuando las im√°genes no est√°n suficientemente depuradas.

Para dar respuesta a estos desaf√≠os, este proyecto propone una **aplicaci√≥n web** capaz de **escanear** y **procesar** autom√°ticamente im√°genes de documentos, brindando herramientas de correcci√≥n de perspectiva y mejoras en la calidad de la imagen. Gracias a la integraci√≥n con librer√≠as de **OCR**, el sistema tambi√©n permite extraer texto de los documentos procesados, reduciendo significativamente el tiempo que se dedica a la introducci√≥n manual de datos.

Con esta soluci√≥n, se busca satisfacer las demandas de un amplio abanico de usuarios y sectores: estudiantes que digitalizan apuntes, profesionales que organizan expedientes, familias que guardan sus facturas e incluso emprendedores que quieren gestionar facturas y recibos de manera ordenada y accesible.

<div class="page"/>

## Objetivo de la Propuesta

### Objetivo Principal

Desarrollar una aplicaci√≥n web que permita el escaneo y procesamiento autom√°tico de documentos utilizando t√©cnicas de visi√≥n por computador, mejorando significativamente la calidad de las im√°genes capturadas.

### Objetivos Espec√≠ficos

- Implementar un sistema de detecci√≥n autom√°tica de documentos utilizando modelos YOLOv11
- Desarrollar algoritmos de correcci√≥n de perspectiva y mejora de imagen
- Integrar capacidades de OCR para la extracci√≥n de texto
- Crear una interfaz web intuitiva y accesible
- Asegurar el funcionamiento completo en el navegador sin necesidad de procesamiento en servidor

<div class="page"/>

## Descripci√≥n T√©cnica

### Desarrollo del Pipeline de Procesamiento en Python

Como paso previo al desarrollo de la aplicaci√≥n web, se implement√≥ un pipeline de procesamiento de im√°genes en Python utilizando OpenCV. Este desarrollo permiti√≥:

1. **Validar el enfoque t√©cnico**: Experimentar con diferentes t√©cnicas de procesamiento de im√°genes y ajustar par√°metros.
2. **Optimizar el flujo de trabajo**: Definir una secuencia clara de pasos para el procesamiento.
3. **Identificar desaf√≠os**: Anticipar problemas potenciales en la implementaci√≥n web.

El pipeline desarrollado en Python incluye los siguientes pasos:

1. **Preprocesamiento**:

   - Redimensionamiento de la imagen manteniendo la proporci√≥n
   - Conversi√≥n a escala de grises
   - Aplicaci√≥n de desenfoque gaussiano para reducir ruido

2. **Detecci√≥n de Bordes y Contornos**:

   - Operaciones morfol√≥gicas (cierre) para mejorar la continuidad de bordes
   - Detecci√≥n de bordes usando Canny
   - B√∫squeda y filtrado de contornos

3. **Identificaci√≥n del Documento**:

   - Aproximaci√≥n de contornos a pol√≠gonos
   - Validaci√≥n de contornos (4 puntos, √°rea m√≠nima)
   - Forzado a 4 puntos si es necesario

4. **Transformaci√≥n de Perspectiva**:

   - Ordenamiento de puntos (superior-izquierda, superior-derecha, etc.)
   - C√°lculo de dimensiones del documento enderezado
   - Aplicaci√≥n de transformaci√≥n de perspectiva

5. **Mejora Final**:
   - Ecualizaci√≥n del histograma
   - Umbralizaci√≥n adaptativa para binarizaci√≥n
   - Ajustes de nitidez

Este desarrollo en Python sirvi√≥ como base para la implementaci√≥n en JavaScript usando OpenCV.js, permitiendo una traducci√≥n directa de los conceptos y algoritmos probados.

![Proceso de transformaci√≥n con OpenCV](assets/opencv.png)

### Pruebas de Concepto con OCR

Como parte del proceso de desarrollo, se realizaron pruebas de concepto con Tesseract para validar la calidad del reconocimiento de texto. Estas pruebas fueron cruciales para:

1. **Evaluar la calidad del OCR**: Comprobar la precisi√≥n del reconocimiento en diferentes tipos de documentos y condiciones.
2. **Optimizar el preprocesamiento**: Ajustar los par√°metros de mejora de imagen para maximizar la precisi√≥n del OCR.
3. **Validar la viabilidad**: Confirmar que Tesseract.js podr√≠a funcionar eficientemente en un entorno web.

Las pruebas demostraron que la calidad del OCR mejora significativamente cuando se aplica el pipeline completo de procesamiento de imagen, especialmente despu√©s de la correcci√≥n de perspectiva y la binarizaci√≥n adaptativa.

<img src="assets/ocr.png" alt="Pruebas de concepto con OCR" width="500">

### Arquitectura del Sistema

El proyecto se estructura en cuatro componentes principales:

1. **M√≥dulo de Mejora de Im√°genes**

   - Implementado con OpenCV.js
   - Incluye detecci√≥n de contornos y correcci√≥n de perspectiva
   - Procesamiento de imagen para optimizar la calidad

2. **Sistema de Detecci√≥n de Documentos**

   - Basado en YOLO y TensorFlow.js
   - Modelo entrenado con dataset espec√≠fico de documentos
   - Adaptaci√≥n para funcionamiento en navegador

   Durante el proceso de exportaci√≥n del modelo YOLOv11n a TensorFlow.js, nos encontramos con un desaf√≠o t√©cnico interesante: la diferencia en el formato de salida entre la inferencia en `Python` y `JavaScript`. Mientras que en `Python` (usando Ultralytics) el modelo devuelve directamente las coordenadas de los bounding boxes procesadas, en `TensorFlow.js` el modelo exportado produce un tensor con forma `[1, 5, 8400]`. Este tensor representa:

   - 8400 posibles detecciones
   - 5 canales de informaci√≥n por cada detecci√≥n (x, y, ancho, alto, confianza)

   Esta diferencia se debe a que TensorFlow.js prioriza la eficiencia y flexibilidad, permitiendo que el post-procesamiento se realice en el lado del cliente seg√∫n las necesidades espec√≠ficas de la aplicaci√≥n. Esta decisi√≥n de dise√±o nos llev√≥ a buscar una soluci√≥n que implemente esta capa adicional de procesamiento en `JavaScript` para interpretar y visualizar las detecciones correctamente.

   Para resolver este desaf√≠o, nos basamos en el trabajo de c√≥digo abierto de [Wahyu Setianto](https://github.com/Hyuto), quien desarroll√≥ una implementaci√≥n eficiente del post-procesamiento de tensores para YOLOv8 en TensorFlow.js. Su soluci√≥n nos permiti√≥ manejar correctamente la salida del modelo y visualizar las detecciones en el navegador.

   Adem√°s, nos enfrentamos a otro desaf√≠o t√©cnico importante relacionado con el manejo de im√°genes de diferentes dimensiones. El modelo YOLO est√° entrenado para trabajar con entradas de 640x640 p√≠xeles, pero las fotograf√≠as tomadas con dispositivos m√≥viles suelen tener dimensiones diferentes (por ejemplo, 1280x720 o 1920x1080). Esto requiri√≥ implementar un proceso de transformaci√≥n de coordenadas que consta de los siguientes pasos:

   1. **Preprocesamiento de la imagen**:

      - C√°lculo del lado m√°ximo entre el ancho y alto de la imagen original
      - Aplicaci√≥n de padding para obtener una imagen cuadrada
      - Reescalado final a 640x640 p√≠xeles

   2. **Transformaci√≥n de coordenadas post-detecci√≥n**:
      - Las coordenadas devueltas por el modelo ([y‚ÇÅ, x‚ÇÅ, y‚ÇÇ, x‚ÇÇ]) est√°n referidas a la imagen 640x640
      - Se calcula el factor de escala: `scale = modelWidth / maxSize`
      - Se revierten las coordenadas al espacio original mediante:
        - Eliminaci√≥n del escalado: `coord_padded = coord_640 / scale`
        - Ajuste a dimensiones reales: `coord_real = max(0, min(sourceDimension, coord_padded))`

   La implementaci√≥n final incluye un manejo robusto de casos especiales, validaciones de dimensiones y soporte tanto para im√°genes est√°ticas como para video en tiempo real. El c√≥digo completo de la funci√≥n de manejo de detecci√≥n est√° disponible en el repositorio.

   Para la exportaci√≥n del modelo a TensorFlow.js utilizamos el siguiente c√≥digo:

   ```python
   from ultralytics import YOLO

   # Load the YOLO11 model
   model = YOLO("/content/detect/docuvision/weights/best.pt")

   # Export the model to TF.js format
   model.export(format="tfjs", simplify=True)  # creates '/best_web_model'
   ```

3. **Motor de OCR**

   - Integraci√≥n de Tesseract.js
   - Capacidades de extracci√≥n de texto
   - Optimizaci√≥n para documentos procesados

4. **Sistema de Despliegue Continuo**

   - Implementaci√≥n de GitHub Actions para despliegue autom√°tico
   - Configuraci√≥n de GitHub Pages como plataforma de hosting
   - Automatizaci√≥n del proceso de build y deploy

   El proyecto utiliza GitHub Actions para automatizar el despliegue a GitHub Pages cada vez que se realiza un push a la rama `master`. El workflow de despliegue:

   - Configura Node.js con cach√© de npm para optimizar el proceso
   - Instala las dependencias usando `npm ci`
   - Construye el proyecto
   - Despliega los archivos generados a la rama `gh-pages`

### Tecnolog√≠as Implementadas

- `OpenCV.js` para procesamiento de im√°genes
- `TensorFlow.js` para la ejecuci√≥n del modelo YOLO
- `Tesseract.js` para OCR
- `JavaScript/HTML5` para la interfaz web
- `WebGL` como backend para la aceleraci√≥n de inferencias
- `GitHub Actions` para integraci√≥n y despliegue continuo
- `GitHub Pages` como plataforma de hosting

<div class="page"/>

## Fuentes y Tecnolog√≠as Utilizadas

### Software

- Visual Studio Code como IDE principal
- Google Colab para el entrenamiento del modelo
- Node.js y Yarn para la gesti√≥n de dependencias del frontend
- Git y GitHub para control de versiones y despliegue autom√°tico
- Vite como herramienta de build

### Hardware

- [Hardware/Sensores utilizados]

### Bibliotecas y Dependencias

- TensorFlow.js con backend WebGL para inferencia en el navegador
- YOLOv11n convertido a formato TensorFlow.js
- Implementaci√≥n base del post-procesamiento de tensores basada en yolov8-tfjs
- gh-pages para el despliegue autom√°tico a GitHub Pages

<div class="page"/>

## Resultados

### Entrenamiento del Modelo

El entrenamiento del modelo se realiz√≥ utilizando YOLOv8n como base, con los siguientes par√°metros:

- 100 √©pocas de entrenamiento
- Tama√±o de imagen: 640x640
- Dataset: Four Corners Detection

Especificaciones del dataset:

- Resoluci√≥n de im√°genes: 640x640 p√≠xeles
- Canales: 3 (RGB)
- Tipo de datos: uint8
- Tama√±o medio por imagen: ~118KB

El proceso de exportaci√≥n del modelo a TensorFlow.js requiri√≥ consideraciones especiales para su uso en el navegador. El modelo exportado produce tensores que requieren post-procesamiento adicional para convertir las predicciones en coordenadas utilizables. Esta caracter√≠stica, aunque inicialmente desafiante, nos permiti√≥ optimizar el rendimiento y personalizar el procesamiento seg√∫n las necesidades espec√≠ficas de nuestra aplicaci√≥n web.

```python
from ultralytics import YOLO

model = YOLO("/content/drive/MyDrive/yolo11n.pt")

train_results = model.train(
    data="data.yaml",
    epochs=100,
    imgsz=640,
    name='docuvision'
)

metrics = model.val()
```

Los resultados de la validaci√≥n del modelo muestran un muy buen rendimiento:

```
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)
                   all        747       1021      0.936      0.897      0.921      0.862
```

El modelo fue evaluado sobre un conjunto de validaci√≥n de 747 im√°genes que conten√≠an 1021 instancias de documentos, obteniendo m√©tricas muy robustas:

- Precisi√≥n (P): 0.936 - Indica que el 93.6% de las detecciones realizadas son correctas
- Recall (R): 0.897 - El modelo es capaz de detectar el 89.7% de todos los documentos presentes
- mAP50: 0.921 - La precisi√≥n media con un IoU (Intersection over Union) del 50% es del 92.1%
- mAP50-95: 0.862 - La precisi√≥n media sobre m√∫ltiples umbrales de IoU es del 86.2%, lo que indica que el modelo es muy preciso en la mayor√≠a de las detecciones.

Estos resultados demuestran que el modelo es altamente preciso en la detecci√≥n de documentos, con un equilibrio √≥ptimo entre precisi√≥n y recall.

### Resultados del Entrenamiento

Las siguientes gr√°ficas muestran las m√©tricas de rendimiento obtenidas durante el entrenamiento:

| **Curva F1**                                                                                                                                                                                         | **Curva de Precisi√≥n**                                                                                                                                        |
| ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| ![Curva F1](detect/docuvision/F1_curve.png)                                                                                                                                                          | ![Curva de Precisi√≥n](detect/docuvision/P_curve.png)                                                                                                          |
| Podemos observar que la curva F1 muestra que el modelo logra un buen equilibrio entre precisi√≥n y recall, alcanzando un valor m√°ximo de 0.92. Esto indica un buen rendimiento general.               | En la curva de precisi√≥n se muestra que el modelo es altamente confiable, logrando hasta un 100% de precisi√≥n en niveles altos de confianza.                  |
| **Curva PR**                                                                                                                                                                                         | **Curva de Recall**                                                                                                                                           |
| ![Curva PR](detect/docuvision/PR_curve.png)                                                                                                                                                          | ![Curva de Recall](detect/docuvision/R_curve.png)                                                                                                             |
| La curva PR demuestra un equilibrio sobresaliente entre precisi√≥n y recall, con un √°rea bajo la curva (mAP) de 0.922, lo que indica un excelente rendimiento en la clasificaci√≥n general del modelo. | La curva de recall muestra que el modelo identifica correctamente el 94% de los casos positivos, siendo muy efectivo incluso con umbrales bajos de confianza. |

### Ejemplo de Inferencia

![Ejemplo de detecci√≥n de documento](assets/inference_example.png)

<div class="page"/>

## Conclusiones y Propuestas de Ampliaci√≥n

### Conclusiones

Este proyecto demuestra la **viabilidad** de una aplicaci√≥n web completamente enfocada en la digitalizaci√≥n de documentos, combinando **OpenCV.js** para correcciones de perspectiva y mejora de im√°genes, **TensorFlow.js** con **YOLOv11** para la detecci√≥n de documentos, y **Tesseract.js** para el OCR. A pesar de su solvencia, el desarrollo no estuvo exento de retos.

En particular, la **exportaci√≥n del modelo YOLOv11n** desde Ultralytics a TensorFlow.js result√≥ un desaf√≠o notable, principalmente debido a la **diferencia en los formatos de salida** y a la necesidad de gestionar coordenadas con dimensiones variables de im√°genes. Fue imprescindible implementar post-procesamientos adicionales en JavaScript, as√≠ como establecer flujos de preprocesamiento y escalado de coordenadas para obtener bounding boxes correctamente localizadas.

El **entrenamiento** con un dataset espec√≠fico y la adaptaci√≥n de t√©cnicas de visi√≥n por computador a la ejecuci√≥n en el navegador subrayan el potencial de estas tecnolog√≠as para soluciones que no dependan de servidores externos. Asimismo, se confirma que la detecci√≥n y correcci√≥n de documentos es factible en entornos web, con resultados precisos y tiempos de inferencia razonables, especialmente gracias al backend **WebGL** de TensorFlow.js.

En definitiva, el proyecto sienta las bases para aplicaciones que requieran un **procesamiento local** en el navegador, al mismo tiempo que evidencia la importancia de la optimizaci√≥n y la correcta gesti√≥n de modelos avanzados de visi√≥n por computador cuando se trasladan a entornos JavaScript.

<div class="page"/>

### Propuestas de Ampliaci√≥n

Dado el enfoque formativo de este proyecto en la asignatura de Visi√≥n por Computador, se identifican varias v√≠as de expansi√≥n que podr√≠an potenciar a√∫n m√°s la calidad y el alcance de la aplicaci√≥n:

1. **Modelos Nativos de TensorFlow.js**

   - Entrenar y optimizar modelos dise√±ados espec√≠ficamente para su ejecuci√≥n con TensorFlow.js, aprovechando los √∫ltimos avances en arquitecturas ligeras (p. ej., MobileNet, EfficientNet) que brindan resultados competitivos con un menor consumo de recursos.
   - Conservar la inferencia en el navegador sin depender de servidores externos, garantizando privacidad y reduciendo la latencia.

2. **Aplicaci√≥n Nativa para M√≥viles**

   - Desarrollar una versi√≥n m√≥vil (Android/iOS) que utilice la aceleraci√≥n de hardware (GPU/TPU integradas) para operaciones de visi√≥n por computador, lo que mejorar√≠a el rendimiento y la velocidad de inferencia respecto a la aplicaci√≥n web.
   - Incorporar reconocimiento de documentos en tiempo real desde la c√°mara, brindando una experiencia de usuario m√°s fluida y sin pasos intermedios de carga o post-procesamiento.

3. **Sistemas de Seguimiento de Movimientos y Estabilizaci√≥n**

   - Integrar t√©cnicas como la detecci√≥n de puntos clave en OpenCV.js o TensorFlow.js para estimar la posici√≥n del tel√©fono o la mano, facilitando una estabilizaci√≥n previa antes de tomar la foto.
   - Reducir im√°genes borrosas o mal enfocadas, mejorando la calidad final de los documentos capturados.

4. **Detecci√≥n de M√∫ltiples P√°ginas y Documentos Compuestos**

   - Extender la l√≥gica de detecci√≥n para identificar varias p√°ginas dentro de una sola foto (p. ej., al escanear un cuaderno o un documento grapado).
   - Dise√±ar un pipeline que permita la segmentaci√≥n de cada p√°gina, su correcci√≥n de perspectiva y la posterior combinaci√≥n en un PDF multi-p√°gina.

5. **Reconocimiento de Texto Avanzado (OCR + NLP)**

   - Explorar el uso de modelos OCR m√°s especializados o un pipeline de Procesamiento de Lenguaje Natural (NLP) para extraer informaci√≥n sem√°ntica (fechas, nombres, importes, etc.) de los documentos.
   - Aplicar t√©cnicas de etiquetado autom√°tico para organizar y clasificar documentos de manera inteligente.

6. **Filtrado y Mejora Avanzada de la Imagen**

   - Investigar nuevas t√©cnicas de desenfoque selectivo, realce adaptativo de contraste o reducci√≥n de ruido basadas en deep learning (p. ej., redes U-Net) para mejorar la legibilidad de documentos.
   - Incluir algoritmos de detecci√≥n de sombras que puedan corregir y eliminar artefactos indeseados en la iluminaci√≥n del documento.

7. **Arquitecturas M√°s Livianas para Dispositivos Limitados**

   - Desarrollar o adaptar modelos con arquitecturas de baja complejidad (Tiny YOLO, MobileNet, etc.) para su uso en dispositivos con menor capacidad de c√≥mputo, asegurando la m√°xima accesibilidad.

8. **Almacenamiento en la Nube y Colaboraci√≥n**

   - Integrar servicios de almacenamiento en la nube (Firebase, Amazon S3, etc.) para que varios usuarios puedan colaborar, anotar y consultar los documentos escaneados en tiempo real.

<div class="page"/>

## Enlaces

- [Enlace al c√≥digo fuente](https://github.com/gitfrandu4/docu-scan)
- [Aplicaci√≥n desplegada](https://gitfrandu4.github.io/docu-scan/)
- [Dataset de entrenamiento](https://universe.roboflow.com/tmayolov8/four-corners-detection)
- [Documentaci√≥n oficial de Ultralytics sobre exportaci√≥n de modelos](https://docs.ultralytics.com/modes/export/)
- [Discusi√≥n sobre diferencias en pre/post-procesamiento de YOLOv8](https://github.com/ultralytics/ultralytics/issues/2451)
- [An√°lisis del post-procesamiento en TensorFlow.js](https://github.com/ultralytics/ultralytics/issues/13413)
- [Gu√≠a de integraci√≥n de TensorFlow.js con YOLO (Espa√±ol)](https://docs.ultralytics.com/es/integrations/tfjs/)
- [Repositorio yolov8-tfjs](https://github.com/Hyuto/yolov8-tfjs) - Implementaci√≥n base para el post-procesamiento de tensores YOLOv8 en TensorFlow.js
- [Documentaci√≥n de GitHub Pages](https://docs.github.com/en/pages)
- [Gu√≠a de Despliegue Est√°tico de Vite](https://vitejs.dev/guide/static-deploy.html)
- [Documentaci√≥n de GitHub Actions](https://docs.github.com/en/actions)

<div class="page"/>

## Cr√©ditos

- Dataset "Four Corners Detection" de Roboflow, utilizado para el entrenamiento del modelo de detecci√≥n de documentos (material no original del grupo)
- Implementaci√≥n base del post-procesamiento de tensores YOLOv8 en TensorFlow.js por Wahyu Setianto
